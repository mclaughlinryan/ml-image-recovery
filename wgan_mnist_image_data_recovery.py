# -*- coding: utf-8 -*-
"""Project_phase_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uEAhiqUYt3b60w2fpHHZ9y1tyIjzNXnG

# Learning GANs from Stochastic Partial Data
#### Dataset: MNIST
#### GAN network: Wasserstein GAN (WGAN) with DCGAN architecture
#### Approach: This framework simulates GAN training on stochastic partial data. Data loss functions (measurement functions) are applied to fully-observed data, invoking various forms of data loss (pixel erasing, low resolving, and addition of Gaussian noise). The discriminator then takes in real and fake images, trying to discern between the two. The real images are the data lossed images (measurement function applied to original data) and the fake images are the output of the measurement function applied to the generator output. Through this process, the framework attempts to learn the measurement function and recover the underlying true data distribution. A Wasserstein loss is used.
### Training/Evaluation:
#### 1) Train network on original data
#### 2) Evaluate network on original data
#### 3) Train new network on partial/imperfect data (measurement function applied)
#### 4) Evaluate that network against original data (compare generator output to original data)
"""

!pip install piq

import torch
import gdown
import os
import numpy as np
import matplotlib.pyplot as plt

import torchvision.transforms as T
from torchvision.io import read_image
import math

from torch import nn
from torch import optim
from torch import Tensor

import random
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.utils.data
import torchvision.utils as vutils
import matplotlib.animation as animation
from IPython.display import HTML

import torchvision.datasets
import torchvision.transforms as transforms
from sklearn.model_selection import train_test_split

# Set random seed for reproducibility
manualSeed = 999
#manualSeed = random.randint(1, 10000) # use if you want new results
print("Random Seed: ", manualSeed)
random.seed(manualSeed)
torch.manual_seed(manualSeed)

dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True,
                               transform=transforms.Compose([
                               transforms.ToTensor(),
                               transforms.Pad(2),
                               transforms.Normalize((0.5), (0.5)),
                            ]))

# Size of training dataset reduced to allow for faster training
# Unperturbed data (for CIFAR10)
# set_fraction = (32000/len(dataset)) # get fraction of data to achieve dataset of 32000 images, which is 1000 batches of 32 images/batch
# set_fraction = (16000/len(dataset)) # get fraction of data to achieve dataset of 16000 images, which is 500 batches of 32 images/batch
# set_fraction = (6400/len(dataset)) # get fraction of data to achieve dataset of 6400 images, which is 200 batches of 32 images/batch
# set_fraction = (4800/len(dataset)) # get fraction of data to achieve dataset of 4800 images, which is 150 batches of 32 images/batch
set_fraction = (3200/len(dataset)) # get fraction of data to achieve dataset of 3200 images, which is 100 batches of 32 images/batch
# set_fraction = (1600/len(dataset)) # get fraction of data to achieve dataset of 1600 images, which is 50 batches of 32 images/batch
# set_fraction = (640/len(dataset)) # get fraction of data to achieve dataset of 640 images, which is 20 batches of 32 images/batch
# set_fraction = (320/len(dataset)) # get fraction of data to achieve dataset of 320 images, which is 10 batches of 32 images/batch
# set_fraction = (96/len(dataset)) # get fraction of data to achieve dataset of 3 batches of 32 images/batch to speed up training
# set_fraction = (32/len(dataset)) # get fraction of data to achieve dataset of 1 batch of 32 images/batch to speed up training
# dataset, testset, _ = torch.utils.data.dataset.random_split(dataset, [int(set_fraction*len(dataset)), int((1/2)*set_fraction*len(dataset)), int(len(dataset)-(3/2)*set_fraction*len(dataset))], generator=torch.Generator().manual_seed(42))

# Unperturbed data (for MNIST)
# set_fraction = (28000/len(dataset)) # get fraction of data to achieve dataset of 28000 images, which is 1000 batches of 28 images/batch
# set_fraction = (14000/len(dataset)) # get fraction of data to achieve dataset of 14000 images, which is 500 batches of 28 images/batch
# set_fraction = (5600/len(dataset)) # get fraction of data to achieve dataset of 5600 images, which is 200 batches of 28 images/batch
# set_fraction = (4200/len(dataset)) # get fraction of data to achieve dataset of 4200 images, which is 150 batches of 28 images/batch
# set_fraction = (2800/len(dataset)) # get fraction of data to achieve dataset of 2800 images, which is 100 batches of 28 images/batch
# set_fraction = (1400/len(dataset)) # get fraction of data to achieve dataset of 1400 images, which is 50 batches of 28 images/batch
# set_fraction = (560/len(dataset)) # get fraction of data to achieve dataset of 560 images, which is 20 batches of 28 images/batch
# set_fraction = (280/len(dataset)) # get fraction of data to achieve dataset of 280 images, which is 10 batches of 28 images/batch
# set_fraction = (84/len(dataset)) # get fraction of data to achieve dataset of 3 batches of 28 images/batch to speed up training
# set_fraction = (28/len(dataset)) # get fraction of data to achieve dataset of 1 batch of 28 images/batch to speed up training

# set_fraction = (57600/len(dataset)) # get fraction of data to achieve dataset of 60000 images, which is 900 batches of 64 images/batch
# set_fraction = (32000/len(dataset)) # get fraction of data to achieve dataset of 32000 images, which is 500 batches of 64 images/batch
# set_fraction = (12800/len(dataset)) # get fraction of data to achieve dataset of 12800 images, which is 200 batches of 64 images/batch
# set_fraction = (9600/len(dataset)) # get fraction of data to achieve dataset of 9600 images, which is 150 batches of 64 images/batch
# set_fraction = (6400/len(dataset)) # get fraction of data to achieve dataset of 6400 images, which is 100 batches of 64 images/batch
# set_fraction = (3200/len(dataset)) # get fraction of data to achieve dataset of 3200 images, which is 50 batches of 64 images/batch
# set_fraction = (1280/len(dataset)) # get fraction of data to achieve dataset of 1280 images, which is 20 batches of 64 images/batch
# set_fraction = (640/len(dataset)) # get fraction of data to achieve dataset of 640 images, which is 10 batches of 64 images/batch
# set_fraction = (192/len(dataset)) # get fraction of data to achieve dataset of 3 batches of 64 images/batch to speed up training
# set_fraction = (64/len(dataset)) # get fraction of data to achieve dataset of 1 batch of 64 images/batch to speed up training

# image parameters for MNIST dataset
# image_size = 28
image_size = 32 # using border padded MNIST data
nc = 1

# Addition of Gaussian noise to image
class transformGaussianNoise():
    def __init__(self, mean=0, std=1):
        self.std = std
        self.mean = mean

    def __call__(self,tensor):
        return tensor + torch.randn(tensor.size())*self.std + self.mean

class transformRandomPixelErasing():
    def __init__(self, p):
        self.p = p

    def __call__(self,img):
        p_matrix = torch.full(img.size(), self.p)
        p_binary = torch.bernoulli(p_matrix).to(torch.bool)
        imgPixelErase = img.clone()
        imgPixelErase[p_binary] = -1
        return imgPixelErase

dataset_noise = torchvision.datasets.MNIST(root='./data', train=True, download=True,
                               transform=transforms.Compose([
                               transforms.ToTensor(),
                               transforms.Pad(2),
                               transforms.Normalize((0.5), (0.5)),
                               transformGaussianNoise(0, 0.2)
                            ]))

dataset_lr = torchvision.datasets.MNIST(root='./data', train=True, download=True,
                               transform=transforms.Compose([
                               transforms.ToTensor(),
                               transforms.Pad(2),
                               transforms.Resize((int)(image_size/2)),
                               transforms.Resize(image_size),
                               transforms.Normalize((0.5), (0.5))
                            ]))

dataset_erase = torchvision.datasets.MNIST(root='./data', train=True, download=True,
                               transform=transforms.Compose([
                               transforms.ToTensor(),
                               transforms.Pad(2),
                               transforms.Normalize((0.5), (0.5)),
                               transformRandomPixelErasing(0.6)
                            ]))

dataset, testset, _ = torch.utils.data.dataset.random_split(dataset, [int(set_fraction*len(dataset)), int((1/2)*set_fraction*len(dataset)), int(len(dataset)-(3/2)*set_fraction*len(dataset))], generator=torch.Generator().manual_seed(42))
dataset_noise, testset_noise, _ = torch.utils.data.dataset.random_split(dataset_noise, [int(set_fraction*len(dataset_noise)), int((1/2)*set_fraction*len(dataset_noise)), int(len(dataset_noise)-(3/2)*set_fraction*len(dataset_noise))], generator=torch.Generator().manual_seed(42))
dataset_lr, testset_lr, _ = torch.utils.data.dataset.random_split(dataset_lr, [int(set_fraction*len(dataset_lr)), int((1/2)*set_fraction*len(dataset_lr)), int(len(dataset_lr)-(3/2)*set_fraction*len(dataset_lr))], generator=torch.Generator().manual_seed(42))
dataset_erase, testset_erase, _ = torch.utils.data.dataset.random_split(dataset_erase, [int(set_fraction*len(dataset_erase)), int((1/2)*set_fraction*len(dataset_erase)), int(len(dataset_erase)-(3/2)*set_fraction*len(dataset_erase))], generator=torch.Generator().manual_seed(42))

# Number of workers for dataloader
workers = 2

# Batch size during training
# batch_size = 64
batch_size = 32
# batch_size = 28
# batch_size = 128

# Spatial size of training images. All images will be resized to this
# size using a transformer.
# image_size = 64
image_size = 32
# image_size = 28

# Number of channels in the training images. For color images this is 3
# nc = 3
nc = 1 # Change to 1 channel if running on MNIST dataset

# Size of z latent vector (i.e. size of generator input)
nz = 100

# Size of feature maps for generator
# ngf = 64
ngf = 32
# ngf = 28

# Size of feature maps for discriminator
# ndf = 64
ndf = 32
# ndf = 28

# Number of training epochs
# num_epochs = 5
# num_epochs = 1
# num_epochs = 10
# num_epochs = 20
num_epochs = 50
# num_epochs = 100
# num_epochs = 150
# num_epochs = 200
# num_epochs = 500
# num_epochs = 1000
# num_epochs = 2000

# Number of evaluation phase epochs
num_epochs_eval = 5
# num_epochs_eval = 10
# num_epochs_eval = 20

# Learning rate for optimizers
lr = 0.0002
# lr = 0.0001

# Beta1 hyperparameter for Adam optimizers
beta1 = 0.5

# Number of GPUs available. Use 0 for CPU mode.
ngpu = 1

# Declare dataloaders
dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,
                                         shuffle=False, num_workers=workers)
dataloader_noise = torch.utils.data.DataLoader(dataset_noise, batch_size=batch_size,
                                         shuffle=False, num_workers=workers)
dataloader_lr = torch.utils.data.DataLoader(dataset_lr, batch_size=batch_size,
                                         shuffle=False, num_workers=workers)
dataloader_erase = torch.utils.data.DataLoader(dataset_erase, batch_size=batch_size,
                                         shuffle=False, num_workers=workers)

# Decide the device to run program on
device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")

# Plot grid of training images
real_batch = next(iter(dataloader))
plt.figure(figsize=(16,16))
plt.axis("off")
plt.title("Training Images (Original dataset)")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:batch_size], padding=2, normalize=True).cpu(),(1,2,0)))

# Plot grid of Gaussian noised images
noise_batch = next(iter(dataloader_noise))
plt.figure(figsize=(16,16))
plt.axis("off")
plt.title("Training Images (Noised dataset)")
plt.imshow(np.transpose(vutils.make_grid(noise_batch[0].to(device)[:batch_size], padding=2, normalize=True).cpu(),(1,2,0)))

# Plot grid of low resolved images
lr_batch = next(iter(dataloader_lr))
plt.figure(figsize=(16,16))
plt.axis("off")
plt.title("Training Images (Low resolved dataset)")
plt.imshow(np.transpose(vutils.make_grid(lr_batch[0].to(device)[:batch_size], padding=2, normalize=True).cpu(),(1,2,0)))

# Plot grid of pixel erased images
erase_batch = next(iter(dataloader_erase))
plt.figure(figsize=(16,16))
plt.axis("off")
plt.title("Training Images (Pixel erased dataset)")
plt.imshow(np.transpose(vutils.make_grid(erase_batch[0].to(device)[:batch_size], padding=2, normalize=True).cpu(),(1,2,0)))

# custom weights initialization for generator and discriminator network
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

# DCGAN generator (for use on border padded MNIST dataset)
class Generator(nn.Module):
    def __init__(self, ngpu):
        super(Generator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d( nz, ngf * 4, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # state size. (ngf*4) x 4 x 4
            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # state size. (ngf*2) x 8 x 8
            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # state size. (ngf) x 16 x 16
            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. (nc) x 32 x 32
        )

    def forward(self, input):
        return self.main(input)

# Create the generator
netG = Generator(ngpu).to(device)

# Handle multi-gpu if desired
if (device.type == 'cuda') and (ngpu > 1):
    netG = nn.DataParallel(netG, list(range(ngpu)))

# Apply weights_init function to randomly initialize all weights
# to mean=0 and stdev=0.02
netG.apply(weights_init)

# Print the model
print(netG)

# DCGAN discriminator altered for WGAN, linear output, no sigmoid activation function (for use on border padded MNIST dataset)
class Discriminator(nn.Module):
    def __init__(self, ngpu):
        super(Discriminator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # intput is (nc) x 32 x 32
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 16 x 16
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 8 x 8
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 4 x 4
            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False)
            # nn.Sigmoid()
        )

    def forward(self, input):
        return self.main(input)

# Create the discriminator
netD = Discriminator(ngpu).to(device)

# Handle multi-gpu if desired
if (device.type == 'cuda') and (ngpu > 1):
    netD = nn.DataParallel(netD, list(range(ngpu)))

# Apply weights_init function to randomly initialize all weights
# to mean=0 and stdev=0.2
netD.apply(weights_init)

# Print the model
print(netD)

# Create batch of latent vectors that will be used to visualize
# progression of the generator
# fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)

# Setup Adam optimizers for G and D
optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))
# optimizerD = optim.RMSprop(netD.parameters(), lr=5e-5)
# optimizerG = optim.RMSprop(netG.parameters(), lr=5e-5)

# Lists to keep track of progress
img_list_real = [[[] for idx1 in range(2)] for idx2 in range(4)]
img_list_fake = [[[] for idx1 in range(2)] for idx2 in range(4)]
G_losses_train = [[] for idx in range(4)]
G_losses_eval = [[] for idx in range(4)]
D_losses_train = [[] for idx in range(4)]
D_losses_eval = [[] for idx in range(4)]

# Commented out IPython magic to ensure Python compatibility.
# WGAN implementation
# Training Loop - Original data
iters = 0

print("Starting Training Loop...")
# For each epoch
for epoch in range(num_epochs):
    # For each batch in the dataloader
    for i, data in enumerate(dataloader, 0):

        # Update D network
        # Train with real batch
        # Format batch
        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)
        netD.zero_grad()

        # Forward pass batch through D
        real_eval = netD(real_cpu)
        errD_real = torch.mean(real_eval)

        # Calculate gradients for D in backward pass
        D_x = real_eval.mean().item()
        errD_real.backward()

        # Train with fake batch
        # Generate batch of latent vectors
        noise = torch.randn(b_size, nz, 1, 1, device=device)

        # Generate fake image batch with G
        imgs_fake = netG(noise)

        # Classify fake batch with D
        fake_eval = netD(imgs_fake)
        errD_fake = -torch.mean(fake_eval)

        # Calculate the gradients for this batch
        D_G_z1 = fake_eval.mean().item()
        errD_fake.backward()

        # Compute error of D as sum over fake and real batches
        errD = errD_real + errD_fake

        # errD.backward()

        # Update D
        optimizerD.step()

        for p in netD.parameters():
            p.data.clamp_(-0.01, 0.01)

        if (i + 1) % 5 == 0:
            # Update G network
            netG.zero_grad()
            imgs_fake = netG(noise)

            # Since we just updated D, perform another forward pass of fake batch through D
            fake_eval = netD(imgs_fake)

            # Calculate G's loss based on this output
            errG = torch.mean(fake_eval)

            # Calculate gradients for G
            errG.backward()
            D_G_z2 = fake_eval.mean().item()

            # Update G
            optimizerG.step()

            # Save Losses to plot later
            G_losses_train[0].append(errG.item())
            D_losses_train[0].append(errD.item())

        # Keep track of generator's performance by saving output
        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                img_list_real[0][0].append(vutils.make_grid(real_cpu.detach().cpu(), padding=2, normalize=True))
                img_list_fake[0][0].append(vutils.make_grid(imgs_fake.detach().cpu(), padding=2, normalize=True))

        iters += 1

    if epoch % 1 == 0:
        print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
#               % (epoch, num_epochs, i, len(dataloader),
                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

# Plot images and network losses from training phase (original dataset)
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list_fake[0][0]]
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)

HTML(ani.to_jshtml())

# Plot real images
plt.figure(figsize=(32,32))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(img_list_real[0][0][-1],(1,2,0)))

# Plot fake images from the last epoch
plt.subplot(1,2,2)
plt.axis("off")
plt.title("Fake Images")
plt.imshow(np.transpose(img_list_fake[0][0][-1],(1,2,0)))
plt.show()

# Plot of Wasserstein loss from networks over the course of training
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses_train[0],label="G")
plt.plot(D_losses_train[0],label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# Evaluation Loop - Original data
iters = 0

netG.eval()
netD.eval()

print("Starting Evaluation Loop...")
# For each epoch
for epoch in range(num_epochs_eval):
    # For each batch in the dataloader
    for i, data in enumerate(dataloader, 0):

        # Update D network
        # Train with real batch
        # Format batch
        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)
        # netD.zero_grad()

        # Forward pass batch through D
        real_eval = netD(real_cpu)
        errD_real = torch.mean(real_eval)

        # Calculate gradients for D in backward pass
        D_x = real_eval.mean().item()
        # errD_real.backward()

        # Train with fake batch
        # Generate batch of latent vectors
        noise = torch.randn(b_size, nz, 1, 1, device=device)

        # Generate fake image batch with G
        imgs_fake = netG(noise)

        # Classify fake batch with D
        fake_eval = netD(imgs_fake)
        errD_fake = -torch.mean(fake_eval)

        D_G_z1 = fake_eval.mean().item()
        # errD_fake.backward()

        # Compute error of D as sum over fake and real batches
        errD = errD_real + errD_fake

        # errD.backward()

        # Update D
        # optimizerD.step()

        for p in netD.parameters():
            p.data.clamp_(-0.01, 0.01)

        if (i + 1) % 5 == 0:
            # Update G network
            # netG.zero_grad()
            imgs_fake = netG(noise)

            # Since we just updated D, perform another forward pass of fake batch through D
            fake_eval = netD(imgs_fake)

            # Calculate G's loss based on this output
            errG = torch.mean(fake_eval)

            # Calculate gradients for G
            # errG.backward()
            D_G_z2 = fake_eval.mean().item()

            # Update G
            # optimizerG.step()

            # Save Losses to plot later
            G_losses_eval[0].append(errG.item())
            D_losses_eval[0].append(errD.item())

        # Keep track of generator's performance by saving output
        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                img_list_real[0][1].append(vutils.make_grid(real_cpu.detach().cpu(), padding=2, normalize=True))
                img_list_fake[0][1].append(vutils.make_grid(imgs_fake.detach().cpu(), padding=2, normalize=True))

        iters += 1

    if epoch % 1 == 0:
        print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
#               % (epoch, num_epochs_eval, i, len(dataloader),
                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

# Plotting images and loss from Evaluation phase (original dataset)
# Plot real images
plt.figure(figsize=(32,32))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(img_list_real[0][1][-1],(1,2,0)))

# Plot fake images from the last epoch
plt.subplot(1,2,2)
plt.axis("off")
plt.title("Fake Images (Generator with no measurement function at output)")
plt.imshow(np.transpose(img_list_fake[0][1][-1],(1,2,0)))
plt.show()

# Plot of Wasserstein loss from networks during Evaluation phase
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Evaluation on Dataset Images")
plt.plot(G_losses_eval[0],label="G")
plt.plot(D_losses_eval[0],label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Network instantiation for training/evaluation phases using a pixel erasing measurement function in AmbientGAN training approach
# Create the generator
netG_erase = Generator(ngpu).to(device)

# Handle multi-gpu if desired
if (device.type == 'cuda') and (ngpu > 1):
    netG_erase  = nn.DataParallel(netG_erase, list(range(ngpu)))

# Apply weights_init function to randomly initialize all weights
# to mean=0 and stdev=0.02
netG_erase.apply(weights_init)

# Create the discriminator
netD_erase = Discriminator(ngpu).to(device)

# Handle multi-gpu if desired
if (device.type == 'cuda') and (ngpu > 1):
    netD_erase = nn.DataParallel(netD_erase, list(range(ngpu)))

# Apply weights_init function to randomly initialize all weights
# to mean=0 and stdev=0.2
netD_erase.apply(weights_init)

# Setup Adam optimizers for G and D
optimizerD = optim.Adam(netD_erase.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG_erase.parameters(), lr=lr, betas=(beta1, 0.999))

# Commented out IPython magic to ensure Python compatibility.
# Training Loop - Pixel erasing measurement function
iters = 0

class transformRandomPixelErasing():
    def __init__(self, p):
        self.p = p

    def __call__(self,img):
        p_matrix = torch.full(img.size(), self.p)
        p_binary = torch.bernoulli(p_matrix).to(torch.bool)
        imgPixelErase = img.clone()
        imgPixelErase[p_binary] = -1
        return imgPixelErase

transformPixelErasing = transforms.Compose([transformRandomPixelErasing(0.6)])

print("Starting Training Loop...")
# For each epoch
for epoch in range(num_epochs):
    # For each batch in the dataloader
    for i, data in enumerate(dataloader_erase, 0):

        # Update D network
        # Train with real batch
        # Format batch
        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)
        netD_erase.zero_grad()

        # Forward pass batch through D
        real_eval = netD_erase(real_cpu)
        errD_real = torch.mean(real_eval)

        # Calculate gradients for D in backward pass
        D_x = real_eval.mean().item()
        errD_real.backward()

        # Train with fake batch
        # Generate batch of latent vectors
        noise = torch.randn(b_size, nz, 1, 1, device=device)

        # Generate fake image batch with G
        imgs_fake = netG_erase(noise)
        imgs_fake = transformPixelErasing(imgs_fake)

        # Classify fake batch with D
        fake_eval = netD_erase(imgs_fake)
        errD_fake = -torch.mean(fake_eval)

        # Calculate the gradients for this batch
        D_G_z1 = fake_eval.mean().item()
        errD_fake.backward()

        # Compute error of D as sum over fake and real batches
        errD = errD_real + errD_fake

        # errD.backward()

        # Update D
        optimizerD.step()

        for p in netD_erase.parameters():
            p.data.clamp_(-0.01, 0.01)

        if (i + 1) % 5 == 0:
            # Update G network
            netG_erase.zero_grad()
            imgs_fake = netG_erase(noise)
            imgs_fake = transformPixelErasing(imgs_fake)

            # Since we just updated D, perform another forward pass of fake batch through D
            fake_eval = netD_erase(imgs_fake)

            # Calculate G's loss based on this output
            errG = torch.mean(fake_eval)

            # Calculate gradients for G
            errG.backward()
            D_G_z2 = fake_eval.mean().item()

            # Update G
            optimizerG.step()

            # Save Losses to plot later
            G_losses_train[1].append(errG.item())
            D_losses_train[1].append(errD.item())

        # Keep track of generator's performance by saving output
        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader_erase)-1)):
            with torch.no_grad():
                img_list_real[1][0].append(vutils.make_grid(real_cpu.detach().cpu(), padding=2, normalize=True))
                img_list_fake[1][0].append(vutils.make_grid(imgs_fake.detach().cpu(), padding=2, normalize=True))

        iters += 1

    if epoch % 1 == 0:
        print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
#               % (epoch, num_epochs, i, len(dataloader_erase),
                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

# Plot images and network losses from training phase (Pixel erasing measurement function)
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list_fake[1][0]]
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)

HTML(ani.to_jshtml())

# Plot real images
plt.figure(figsize=(32,32))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(img_list_real[1][0][-1],(1,2,0)))

# Plot fake images from the last epoch
plt.subplot(1,2,2)
plt.axis("off")
plt.title("Fake Images")
plt.imshow(np.transpose(img_list_fake[1][0][-1],(1,2,0)))
plt.show()

# Plot of Wasserstein loss from networks over the course of training
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses_train[1],label="G")
plt.plot(D_losses_train[1],label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# Evaluation Loop - Pixel erasing measurement function
iters = 0

netG_erase.eval()
netD.eval()

print("Starting Evaluation Loop...")
# For each epoch
for epoch in range(num_epochs_eval):
    # For each batch in the dataloader
    for i, data in enumerate(dataloader, 0):

        # Update D network
        # Train with real batch
        # Format batch
        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)
        # netD.zero_grad()

        # Forward pass batch through D
        real_eval = netD(real_cpu)
        errD_real = torch.mean(real_eval)

        # Calculate gradients for D in backward pass
        D_x = real_eval.mean().item()
        # errD_real.backward()

        # Train with fake batch
        # Generate batch of latent vectors
        noise = torch.randn(b_size, nz, 1, 1, device=device)

        # Generate fake image batch with G
        imgs_fake = netG_erase(noise)

        # Classify fake batch with D
        fake_eval = netD(imgs_fake)
        errD_fake = -torch.mean(fake_eval)

        D_G_z1 = fake_eval.mean().item()
        # errD_fake.backward()

        # Compute error of D as sum over fake and real batches
        errD = errD_real + errD_fake

        # errD.backward()

        # Update D
        # optimizerD.step()

        for p in netD.parameters():
            p.data.clamp_(-0.01, 0.01)

        if (i + 1) % 5 == 0:
            # Update G network
            # netG.zero_grad()
            imgs_fake = netG_erase(noise)

            # Since we just updated D, perform another forward pass of fake batch through D
            fake_eval = netD(imgs_fake)

            # Calculate G's loss based on this output
            errG = torch.mean(fake_eval)

            # Calculate gradients for G
            # errG.backward()
            D_G_z2 = fake_eval.mean().item()

            # Update G
            # optimizerG.step()

            # Save Losses to plot later
            G_losses_eval[1].append(errG.item())
            D_losses_eval[1].append(errD.item())

        # Keep track of generator's performance by saving output
        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                img_list_real[1][1].append(vutils.make_grid(real_cpu.detach().cpu(), padding=2, normalize=True))
                img_list_fake[1][1].append(vutils.make_grid(imgs_fake.detach().cpu(), padding=2, normalize=True))

        iters += 1

    if epoch % 1 == 0:
        print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
#               % (epoch, num_epochs_eval, i, len(dataloader),
                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

# Plotting images and loss from Evaluation phase (using pixel erased-trained network)
# Plot real images
plt.figure(figsize=(32,32))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(img_list_real[1][1][-1],(1,2,0)))

# Plot fake images from the last epoch
plt.subplot(1,2,2)
plt.axis("off")
plt.title("Fake Images (Generator with Gaussian noise measurement function at output)")
plt.imshow(np.transpose(img_list_fake[1][1][-1],(1,2,0)))
plt.show()

# Plot of Wasserstein loss from networks during Evaluation phase
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Evaluation on Gaussian noise images")
plt.plot(G_losses_eval[1],label="G")
plt.plot(D_losses_eval[1],label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Network instantiation for training/evaluation phases using a low resolve measurement function in AmbientGAN training approach
# Create the generator
netG_lr = Generator(ngpu).to(device)

# Handle multi-gpu if desired
if (device.type == 'cuda') and (ngpu > 1):
    netG_lr  = nn.DataParallel(netG_lr, list(range(ngpu)))

# Apply weights_init function to randomly initialize all weights
# to mean=0 and stdev=0.02
netG_lr.apply(weights_init)

# Create the discriminator
netD_lr = Discriminator(ngpu).to(device)

# Handle multi-gpu if desired
if (device.type == 'cuda') and (ngpu > 1):
    netD_lr = nn.DataParallel(netD_lr, list(range(ngpu)))

# Apply weights_init function to randomly initialize all weights
# to mean=0 and stdev=0.2
netD_lr.apply(weights_init)

# Setup Adam optimizers for G and D
optimizerD = optim.Adam(netD_lr.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG_lr.parameters(), lr=lr, betas=(beta1, 0.999))

# Commented out IPython magic to ensure Python compatibility.
# Training Loop - Low resolve measurement function
iters = 0

resizeTransform_ds = transforms.Resize((int)(image_size/2))
resizeTransform_us = transforms.Resize(image_size)

print("Starting Training Loop...")
# For each epoch
for epoch in range(num_epochs):
    # For each batch in the dataloader
    for i, data in enumerate(dataloader_lr, 0):

        # Update D network
        # Train with real batch
        # Format batch
        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)
        netD_lr.zero_grad()

        # Forward pass batch through D
        real_eval = netD_lr(real_cpu)
        errD_real = torch.mean(real_eval)

        # Calculate gradients for D in backward pass
        D_x = real_eval.mean().item()
        errD_real.backward()

        # Train with fake batch
        # Generate batch of latent vectors
        noise = torch.randn(b_size, nz, 1, 1, device=device)

        # Generate fake image batch with G
        imgs_fake = netG_lr(noise)
        imgs_fake = resizeTransform_ds(imgs_fake)
        imgs_fake = resizeTransform_us(imgs_fake)

        # Classify fake batch with D
        fake_eval = netD_lr(imgs_fake)
        errD_fake = -torch.mean(fake_eval)

        # Calculate the gradients for this batch
        D_G_z1 = fake_eval.mean().item()
        errD_fake.backward()

        # Compute error of D as sum over fake and real batches
        errD = errD_real + errD_fake

        # errD.backward()

        # Update D
        optimizerD.step()

        for p in netD_lr.parameters():
            p.data.clamp_(-0.01, 0.01)

        if (i + 1) % 5 == 0:
            # Update G network
            netG_lr.zero_grad()
            imgs_fake = netG(noise)
            imgs_fake = resizeTransform_ds(imgs_fake)
            imgs_fake = resizeTransform_us(imgs_fake)

            # Since we just updated D, perform another forward pass of fake batch through D
            fake_eval = netD_lr(imgs_fake)

            # Calculate G's loss based on this output
            errG = torch.mean(fake_eval)

            # Calculate gradients for G
            errG.backward()
            D_G_z2 = fake_eval.mean().item()

            # Update G
            optimizerG.step()

            # Save Losses to plot later
            G_losses_train[2].append(errG.item())
            D_losses_train[2].append(errD.item())

        # Keep track of generator's performance by saving output
        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader_lr)-1)):
            with torch.no_grad():
                img_list_real[2][0].append(vutils.make_grid(real_cpu.detach().cpu(), padding=2, normalize=True))
                img_list_fake[2][0].append(vutils.make_grid(imgs_fake.detach().cpu(), padding=2, normalize=True))

        iters += 1

    if epoch % 1 == 0:
        print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
#               % (epoch, num_epochs, i, len(dataloader_lr),
                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

# Plot images and network losses from training phase
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list_fake[2][0]]
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)

HTML(ani.to_jshtml())

# Plot real images
plt.figure(figsize=(32,32))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(img_list_real[2][0][-1],(1,2,0)))

# Plot fake images from the last epoch
plt.subplot(1,2,2)
plt.axis("off")
plt.title("Fake Images")
plt.imshow(np.transpose(img_list_fake[2][0][-1],(1,2,0)))
plt.show()

# Plot of Wasserstein loss from networks over the course of training
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses_train[2],label="G")
plt.plot(D_losses_train[2],label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# Evaluation Loop - Low resolve measurement function
iters = 0

netG_lr.eval()
netD.eval()

print("Starting Evaluation Loop...")
# For each epoch
for epoch in range(num_epochs_eval):
    # For each batch in the dataloader
    for i, data in enumerate(dataloader, 0):

        # Update D network
        # Train with real batch
        # Format batch
        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)
        # netD.zero_grad()

        # Forward pass batch through D
        real_eval = netD(real_cpu)
        errD_real = torch.mean(real_eval)

        # Calculate gradients for D in backward pass
        D_x = real_eval.mean().item()
        # errD_real.backward()

        # Train with fake batch
        # Generate batch of latent vectors
        noise = torch.randn(b_size, nz, 1, 1, device=device)

        # Generate fake image batch with G
        imgs_fake = netG_lr(noise)

        # Classify fake batch with D
        fake_eval = netD(imgs_fake)
        errD_fake = -torch.mean(fake_eval)

        D_G_z1 = fake_eval.mean().item()
        # errD_fake.backward()

        # Compute error of D as sum over fake and real batches
        errD = errD_real + errD_fake

        # errD.backward()

        # Update D
        # optimizerD.step()

        for p in netD.parameters():
            p.data.clamp_(-0.01, 0.01)

        if (i + 1) % 5 == 0:
            # Update G network
            # netG.zero_grad()
            imgs_fake = netG_lr(noise)

            # Since we just updated D, perform another forward pass of fake batch through D
            fake_eval = netD(imgs_fake)

            # Calculate G's loss based on this output
            errG = -torch.mean(fake_eval)

            # Calculate gradients for G
            # errG.backward()
            D_G_z2 = fake_eval.mean().item()

            # Update G
            # optimizerG.step()

            # Save Losses to plot later
            G_losses_eval[2].append(errG.item())
            D_losses_eval[2].append(errD.item())

        # Keep track of generator's performance by saving output
        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                img_list_real[2][1].append(vutils.make_grid(real_cpu.detach().cpu(), padding=2, normalize=True))
                img_list_fake[2][1].append(vutils.make_grid(imgs_fake.detach().cpu(), padding=2, normalize=True))

        iters += 1

    if epoch % 1 == 0:
        print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
#               % (epoch, num_epochs_eval, i, len(dataloader),
                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

# Plotting images and loss from Evaluation phase (using low resolution-trained nework)
# Plot real images
plt.figure(figsize=(32,32))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(img_list_real[2][1][-1],(1,2,0)))

# Plot fake images from the last epoch
plt.subplot(1,2,2)
plt.axis("off")
plt.title("Fake Images (Generator with no measurement function at output)")
plt.imshow(np.transpose(img_list_fake[2][1][-1],(1,2,0)))
plt.show()

# Plot of Wasserstein loss from networks during Evaluation phase
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Evaluation on Dataset Images")
plt.plot(G_losses_eval[2],label="G")
plt.plot(D_losses_eval[2],label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Network instantiation for training/evaluation phases using a Gaussian noise measurement function in AmbientGAN training approach
# Create the generator
netG_noise = Generator(ngpu).to(device)

# Handle multi-gpu if desired
if (device.type == 'cuda') and (ngpu > 1):
    netG_noise  = nn.DataParallel(netG_noise, list(range(ngpu)))

# Apply weights_init function to randomly initialize all weights
# to mean=0 and stdev=0.02
netG_noise.apply(weights_init)

# Create the discriminator
netD_noise = Discriminator(ngpu).to(device)

# Handle multi-gpu if desired
if (device.type == 'cuda') and (ngpu > 1):
    netD_noise = nn.DataParallel(netD_noise, list(range(ngpu)))

# Apply weights_init function to randomly initialize all weights
# to mean=0 and stdev=0.2
netD_noise.apply(weights_init)

# Setup Adam optimizers for G and D
optimizerD = optim.Adam(netD_noise.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG_noise.parameters(), lr=lr, betas=(beta1, 0.999))

# Commented out IPython magic to ensure Python compatibility.
# Training Loop - Gaussian noise measurement function
iters = 0

# Addition of Gaussian noise to image
class transformGaussianNoise():
    def __init__(self, mean=0, std=1):
        self.std = std
        self.mean = mean

    def __call__(self,tensor):
        return tensor + torch.randn(tensor.size())*self.std + self.mean

transformAddNoise = transforms.Compose([transformGaussianNoise(0, 0.2)])

print("Starting Training Loop...")
# For each epoch
for epoch in range(num_epochs):
    # For each batch in the dataloader
    for i, data in enumerate(dataloader_noise, 0):

        # Update D network
        # Train with real batch
        # Format batch
        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)
        netD_noise.zero_grad()

        # Forward pass batch through D
        real_eval = netD_noise(real_cpu)
        errD_real = torch.mean(real_eval)

        # Calculate gradients for D in backward pass
        D_x = real_eval.mean().item()
        errD_real.backward()

        # Train with fake batch
        # Generate batch of latent vectors
        noise = torch.randn(b_size, nz, 1, 1, device=device)

        # Generate fake image batch with G
        imgs_fake = netG_noise(noise)
        imgs_fake = transformAddNoise(imgs_fake)

        # Classify fake batch with D
        fake_eval = netD_noise(imgs_fake)
        errD_fake = -torch.mean(fake_eval)

        # Calculate the gradients for this batch
        D_G_z1 = fake_eval.mean().item()
        errD_fake.backward()

        # Compute error of D as sum over fake and real batches
        errD = errD_real + errD_fake

        # errD.backward()

        # Update D
        optimizerD.step()

        for p in netD_noise.parameters():
            p.data.clamp_(-0.01, 0.01)

        if (i + 1) % 5 == 0:
            # Update G network
            netG.zero_grad()
            imgs_fake = netG_noise(noise)
            imgs_fake = transformAddNoise(imgs_fake)

            # Since we just updated D, perform another forward pass of fake batch through D
            fake_eval = netD_noise(imgs_fake)

            # Calculate G's loss based on this output
            errG = torch.mean(fake_eval)

            # Calculate gradients for G
            errG.backward()
            D_G_z2 = fake_eval.mean().item()

            # Update G
            optimizerG.step()

            # Save Losses to plot later
            G_losses_train[3].append(errG.item())
            D_losses_train[3].append(errD.item())

        # Keep track of generator's performance by saving output
        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader_noise)-1)):
            with torch.no_grad():
                img_list_real[3][0].append(vutils.make_grid(real_cpu.detach().cpu(), padding=2, normalize=True))
                img_list_fake[3][0].append(vutils.make_grid(imgs_fake.detach().cpu(), padding=2, normalize=True))

        iters += 1

    if epoch % 1 == 0:
        print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
#               % (epoch, num_epochs, i, len(dataloader_noise),
                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

# Plot images and network losses from training phase
fig = plt.figure(figsize=(8,8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list_fake[3][0]]
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)

HTML(ani.to_jshtml())

# Plot real images
plt.figure(figsize=(32,32))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(img_list_real[3][0][-1],(1,2,0)))

# Plot fake images from the last epoch
plt.subplot(1,2,2)
plt.axis("off")
plt.title("Fake Images")
plt.imshow(np.transpose(img_list_fake[3][0][-1],(1,2,0)))
plt.show()

# Plot of Wasserstein loss from networks over the course of training
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses_train[3],label="G")
plt.plot(D_losses_train[3],label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# Evaluation Loop - Gaussian noise measurement function
iters = 0

netG_noise.eval()
netD.eval()

print("Starting Evaluation Loop...")
# For each epoch
for epoch in range(num_epochs_eval):
    # For each batch in the dataloader
    for i, data in enumerate(dataloader, 0):

        # Update D network
        # Train with real batch
        # Format batch
        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)
        # netD.zero_grad()

        # Forward pass batch through D
        real_eval = netD(real_cpu)
        errD_eral = torch.mean(real_eval)

        # Calculate gradients for D in backward pass
        D_x = real_eval.mean().item()
        # errD_real.backward()

        # Train with fake batch
        # Generate batch of latent vectors
        noise = torch.randn(b_size, nz, 1, 1, device=device)

        # Generate fake image batch with G
        imgs_fake = netG_noise(noise)

        # Classify fake batch with D
        fake_eval = netD(imgs_fake)
        errD_fake = -torch.mean(fake_eval)

        D_G_z1 = fake_eval.mean().item()
        # errD_fake.backward()

        # Compute error of D as sum over fake and real batches
        errD = errD_real + errD_fake

        # errD.backward()

        # Update D
        # optimizerD.step()

        for p in netD.parameters():
            p.data.clamp_(-0.01, 0.01)

        if (i + 1) % 5 == 0:
            # Update G network
            # netG.zero_grad()
            imgs_fake = netG_noise(noise)

            # Since we just updated D, perform another forward pass of fake batch through D
            fake_eval = netD(imgs_fake)

            # Calculate G's loss based on this output
            errG = torch.mean(fake_eval)

            # Calculate gradients for G
            # errG.backward()
            D_G_z2 = fake_eval.mean().item()

            # Update G
            # optimizerG.step()

            # Save Losses to plot later
            G_losses_train[3].append(errG.item())
            D_losses_train[3].append(errD.item())

        # Keep track of generator's performance by saving output
        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                img_list_real[3][1].append(vutils.make_grid(real_cpu.detach().cpu(), padding=2, normalize=True))
                img_list_fake[3][1].append(vutils.make_grid(imgs_fake.detach().cpu(), padding=2, normalize=True))

        iters += 1

    if epoch % 1 == 0:
        print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
#               % (epoch, num_epochs_eval, i, len(dataloader),
                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

# Plotting images and loss from Evaluation phase (using Gaussian noise-trained nework)
# Plot real images
plt.figure(figsize=(32,32))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(img_list_real[3][1][-1],(1,2,0)))

# Plot fake images from the last epoch
plt.subplot(1,2,2)
plt.axis("off")
plt.title("Fake Images (Generator with no measurement function at output)")
plt.imshow(np.transpose(img_list_fake[3][1][-1],(1,2,0)))
plt.show()

# Plot of Wasserstein loss from networks during Evaluation phase
plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Evaluation on Dataset Images")
plt.plot(G_losses_eval[3],label="G")
plt.plot(D_losses_eval[3],label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()